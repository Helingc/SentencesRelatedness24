{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcZpv71Fnxdz"
      },
      "source": [
        "*  Using microsoft guidance library to force desired output format\n",
        "*  Using TheBloke C++ quantized LLAMA2 version to reduce RAM & vRAM requirements\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUYyGjkQrpDh",
        "outputId": "25c9af20-d044-4fb0-f2e1-dafdde16de0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting download of llama-2-7b-chat.Q3_K_L.gguf\n",
            "[██████████████████████████████████████████████████] 100.00%\n",
            "Download completed.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "# Downloading desired model\n",
        "def download_file_with_progress(url, filename):\n",
        "    \"\"\"\n",
        "    Download a file with progress indicator from a given URL\n",
        "\n",
        "    :param url: URL to the file\n",
        "    :param filename: Filename to save the downloaded content\n",
        "    \"\"\"\n",
        "    response = requests.get(url, stream=True)\n",
        "    total_size_in_bytes = int(response.headers.get('content-length', 0))\n",
        "    block_size = 1024*1024*100 # 100 megabites chunks\n",
        "    progress_bar_size = 50\n",
        "    print(f\"Starting download of {filename}\")\n",
        "\n",
        "    with open(filename, 'wb') as file:\n",
        "        downloaded_size = 0\n",
        "        for data in response.iter_content(block_size):\n",
        "            downloaded_size += len(data)\n",
        "            file.write(data)\n",
        "            done = int(progress_bar_size * downloaded_size / total_size_in_bytes)\n",
        "            print(f\"\\r[{'█' * done}{'.' * (progress_bar_size - done)}] {downloaded_size * 100 / total_size_in_bytes:.2f}%\", end = '')\n",
        "    print(\"\\nDownload completed.\")\n",
        "\n",
        "# URL to the .gguf file\n",
        "gguf_url = \"https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/resolve/main/llama-2-7b-chat.Q3_K_L.gguf?download=true\"\n",
        "\n",
        "# Local filename to save the .gguf file\n",
        "gguf_filename = \"llama-2-7b-chat.Q3_K_L.gguf\"\n",
        "\n",
        "# Download the .gguf file with progress\n",
        "download_file_with_progress(gguf_url, gguf_filename)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCXxL6nOsVuB",
        "outputId": "fa21902e-a43c-4708-dc75-9846b281bd8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-cpp-python\n",
            "  Downloading llama_cpp_python-0.2.26.tar.gz (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (4.5.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (1.23.5)\n",
            "Requirement already satisfied: diskcache>=5.6.1 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (5.6.3)\n",
            "Building wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.26-cp310-cp310-manylinux_2_35_x86_64.whl size=8130346 sha256=e7f107fdcc1357a959a1fed8f24b07eafc89cccef4e793c70ac0656c199d284c\n",
            "  Stored in directory: /root/.cache/pip/wheels/91/80/ce/ac6afea8c1d6fbcec7e14183033a5b2796c742d4f470010c72\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: llama-cpp-python\n",
            "Successfully installed llama-cpp-python-0.2.26\n",
            "Collecting guidance\n",
            "  Downloading guidance-0.1.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (229 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.3/229.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: diskcache in /usr/local/lib/python3.10/dist-packages (from guidance) (5.6.3)\n",
            "Collecting gptcache (from guidance)\n",
            "  Downloading gptcache-0.1.43-py3-none-any.whl (131 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.5/131.5 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai>=1.0 (from guidance)\n",
            "  Downloading openai-1.6.1-py3-none-any.whl (225 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.4/225.4 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from guidance) (4.1.0)\n",
            "Collecting tiktoken>=0.3 (from guidance)\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting msal (from guidance)\n",
            "  Downloading msal-1.26.0-py2.py3-none-any.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.0/99.0 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from guidance) (2.31.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from guidance) (1.23.5)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from guidance) (3.9.1)\n",
            "Collecting ordered-set (from guidance)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Collecting pyformlang (from guidance)\n",
            "  Downloading pyformlang-1.0.4-py3-none-any.whl (124 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.7/124.7 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.0->guidance) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.0->guidance) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai>=1.0->guidance)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.0->guidance) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.0->guidance) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai>=1.0->guidance) (4.66.1)\n",
            "Collecting typing-extensions<5,>=4.7 (from openai>=1.0->guidance)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken>=0.3->guidance) (2023.6.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->guidance) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->guidance) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->guidance) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->guidance) (2023.11.17)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->guidance) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->guidance) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->guidance) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->guidance) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->guidance) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->guidance) (4.0.3)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from gptcache->guidance) (5.3.2)\n",
            "Requirement already satisfied: PyJWT[crypto]<3,>=1.0.0 in /usr/lib/python3/dist-packages (from msal->guidance) (2.3.0)\n",
            "Requirement already satisfied: cryptography<44,>=0.6 in /usr/local/lib/python3.10/dist-packages (from msal->guidance) (41.0.7)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pyformlang->guidance) (3.2.1)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.10/dist-packages (from pyformlang->guidance) (1.4.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.0->guidance) (1.2.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography<44,>=0.6->msal->guidance) (1.16.0)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai>=1.0->guidance)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.0->guidance)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from pydot->pyformlang->guidance) (3.1.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography<44,>=0.6->msal->guidance) (2.21)\n",
            "Installing collected packages: typing-extensions, ordered-set, h11, tiktoken, pyformlang, httpcore, gptcache, httpx, openai, msal, guidance\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gptcache-0.1.43 guidance-0.1.10 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 msal-1.26.0 openai-1.6.1 ordered-set-4.1.0 pyformlang-1.0.4 tiktoken-0.5.2 typing-extensions-4.9.0\n"
          ]
        }
      ],
      "source": [
        "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python\n",
        "!pip install guidance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uddV4IyKn1M7",
        "outputId": "0cd40fde-4a62-41f9-c431-ed4e40514127"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:guidance.models.llama_cpp._llama_cpp:Cannot use verbose=True in this context (probably CoLab). See https://github.com/abetlen/llama-cpp-python/issues/729\n",
            "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n"
          ]
        }
      ],
      "source": [
        "import guidance\n",
        "from guidance import models, gen, system, user, assistant\n",
        "\n",
        "# Model needs to be locally saved\n",
        "# A sample model can be downloaded from\n",
        "# https://huggingface.co/TheBloke/Llama-2-7B-GGUF/blob/main/llama-2-7b.Q5_K_M.gguf\n",
        "\n",
        "gguf_filename = \"llama-2-7b-chat.Q3_K_L.gguf\"\n",
        "llama2 = models.LlamaCpp(gguf_filename, n_gpu_layers=-1, n_ctx=4096)\n",
        "\n",
        "# BLAS = 1 means there is GPU acceleration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "YZ_fG4RWqKqZ",
        "outputId": "9ae002d7-70c4-4919-8f0e-faa092c923a5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style='margin: 0px; padding: 0px; vertical-align: middle; padding-left: 8px; margin-left: -8px; border-radius: 0px; border-left: 1px solid rgba(127, 127, 127, 0.2); white-space: pre-wrap; font-family: ColfaxAI, Arial; font-size: 15px; line-height: 23px;'>        Q: How semantically similar are those two sentences on scale from 0 to 1: [Dogs eat bones, Dog is green]\n",
              "        A:<span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'> </span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>0</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>.</span><span style='background-color: rgba(0.0, 165.0, 0, 0.15); border-radius: 3px;' title='1.0'>5</span></pre>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 456 ms, sys: 2.81 ms, total: 459 ms\n",
            "Wall time: 471 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "regex_pattern = r\"0(\\.\\d+)?|1(\\.0+)?\" # accept output as a float from 0 to 1\n",
        "\n",
        "sentence_pair = \"[Dogs eat bones, Dog is green]\"\n",
        "query = f\"\"\"How semantically similar are those two sentences on scale from 0 to 1: {sentence_pair}\"\"\"\n",
        "\n",
        "output = llama2 + f'''\\\n",
        "        Q: {query}\n",
        "        A: {gen('similarity', regex=regex_pattern)}'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output[\"similarity\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "0-ESkBOdwX0j",
        "outputId": "ce8dac06-2a2e-4368-a2e6-e8c7303a1f1e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "nIuczIigyI5s",
        "outputId": "f7817b0f-a7a0-44b9-8c2f-f343b6cc22a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "           PairID                                               Text  Score  \\\n",
              "0  ENG-train-0000  It that happens, just pull the plug.\\r\\nif tha...    1.0   \n",
              "1  ENG-train-0001  A black dog running through water.\\r\\nA black ...    1.0   \n",
              "2  ENG-train-0002  I've been searchingthe entire abbey for you.\\r...    1.0   \n",
              "3  ENG-train-0003  If he is good looking and has a good personali...    1.0   \n",
              "4  ENG-train-0004  She does not hate you, she is just annoyed wit...    1.0   \n",
              "\n",
              "                                               sen_1  \\\n",
              "0                It that happens just pull the plug    \n",
              "1                 A black dog running through water    \n",
              "2       I ve been searchingthe entire abbey for you    \n",
              "3  If he is good looking and has a good personali...   \n",
              "4  She does not hate you she is just annoyed with...   \n",
              "\n",
              "                                               sen_2  \n",
              "0           if that ever happens just pull the plug   \n",
              "1         A black dog is running through some water   \n",
              "2            I m looking for you all over the abbey   \n",
              "3   If he s good looking and a good personality h...  \n",
              "4          She doesn t hate you she is just annoyed   "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-16ec795c-e6c1-4162-b81f-c66dc181474b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PairID</th>\n",
              "      <th>Text</th>\n",
              "      <th>Score</th>\n",
              "      <th>sen_1</th>\n",
              "      <th>sen_2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ENG-train-0000</td>\n",
              "      <td>It that happens, just pull the plug.\\r\\nif tha...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>It that happens just pull the plug</td>\n",
              "      <td>if that ever happens just pull the plug</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENG-train-0001</td>\n",
              "      <td>A black dog running through water.\\r\\nA black ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>A black dog running through water</td>\n",
              "      <td>A black dog is running through some water</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ENG-train-0002</td>\n",
              "      <td>I've been searchingthe entire abbey for you.\\r...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>I ve been searchingthe entire abbey for you</td>\n",
              "      <td>I m looking for you all over the abbey</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ENG-train-0003</td>\n",
              "      <td>If he is good looking and has a good personali...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>If he is good looking and has a good personali...</td>\n",
              "      <td>If he s good looking and a good personality h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ENG-train-0004</td>\n",
              "      <td>She does not hate you, she is just annoyed wit...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>She does not hate you she is just annoyed with...</td>\n",
              "      <td>She doesn t hate you she is just annoyed</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16ec795c-e6c1-4162-b81f-c66dc181474b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-16ec795c-e6c1-4162-b81f-c66dc181474b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-16ec795c-e6c1-4162-b81f-c66dc181474b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-89aab2fe-839f-4680-9273-81ac04d2894b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-89aab2fe-839f-4680-9273-81ac04d2894b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-89aab2fe-839f-4680-9273-81ac04d2894b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Get data\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    PATH = os.path.join(\"drive\", \"MyDrive\", \"LMU\", \"AppliedDL\", \"data\", \"raw\")\n",
        "\n",
        "\n",
        "def get_data(subset):\n",
        "\n",
        "    df_train = pd.read_csv(os.path.join(PATH, 'eng_train.csv'))\n",
        "    df_train[\"Split_Text\"] = df_train[\"Text\"].apply(lambda x: x.replace(\"\\n\", \" \"))\n",
        "    df_train['Split_Text'] = df_train['Split_Text'].apply(lambda x: x.split(\"\\r\"))\n",
        "    df_train['Split_Text'] = df_train['Split_Text'].apply(lambda x: [re.sub(r\"[^a-zA-Z0-9]+\", ' ', k) for k in x])\n",
        "\n",
        "    df_train[\"sen_1\"] = df_train[\"Split_Text\"].apply(lambda x: x[0])\n",
        "    df_train[\"sen_2\"] = df_train[\"Split_Text\"].apply(lambda x: x[1])\n",
        "    df_train.drop([\"Split_Text\"], axis=1, inplace=True)\n",
        "    display(df_train.head())\n",
        "\n",
        "    if subset is not None:\n",
        "        df_train = df_train.sample(n=subset, random_state=42)\n",
        "\n",
        "    return df_train\n",
        "\n",
        "df = get_data(subset=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4Bq_Tqmy4eN",
        "outputId": "a1b3b41b-9ada-4a5d-e549-cf432fd4567a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I wanted to know why Shiarra was being dragged into this and the petty excuse just made my day ,  As much as I want to strangle Shiarra I really like the other characters so I am sticking with it ] = 0.41, [Hold her neck with soft hands and kiss her on the back of her ear ,  Hold hands snuggle give her kisses and hug her tightly ] = 0.88, [A group of protesters carrying signs and flags walk down the street ,  A man with a cap and jeans is washing the window not on ground level ] = 0.16 \n",
            "\n",
            " ('[a skateboarder jumps over a set of stairs ,  A little girl swimming in a pool ]', 0.22)\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def get_list(df, n, score_sep = False):\n",
        "\n",
        "    ints = random.sample(range(len(df)), n)\n",
        "\n",
        "    if score_sep == False:\n",
        "\n",
        "        sen_list = []\n",
        "        for i in ints:\n",
        "            prompt = f'[{df.iloc[i, 3]}, {df.iloc[i, 4]}] = {df.iloc[i, 2]}'\n",
        "            sen_list.append(prompt)\n",
        "\n",
        "        return (\", \").join(sen_list)\n",
        "\n",
        "    else:\n",
        "        i = ints[0]\n",
        "        sentences = f'[{df.iloc[i, 3]}, {df.iloc[i, 4]}]'\n",
        "        score = df.iloc[i, 2]\n",
        "\n",
        "        return sentences, score\n",
        "\n",
        "\n",
        "print(get_list(df, 3), \"\\n\\n\", get_list(df, 3, score_sep = True))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "regex_pattern = r\"0(\\.\\d+)?|1(\\.0+)?\" # accept output as a float from 0 to 1\n",
        "\n",
        "results = []\n",
        "\n",
        "# Iterate through the loop\n",
        "for i in tqdm(range(len(df))):\n",
        "    sentence_pair = f'[{df.iloc[i, 3]}, {df.iloc[i, 4]}]'\n",
        "    score = df.iloc[i, 2]\n",
        "\n",
        "    query = f\"\"\"How semantically related are those two sentences on scale from 0 to 1: {sentence_pair}\"\"\"\n",
        "\n",
        "    output = llama2 + f'''\\\n",
        "        Q: {query}\n",
        "        A: {gen('relatedness', regex=regex_pattern)}'''\n",
        "\n",
        "    # Append the results to the list\n",
        "    results.append((score, float(output[\"relatedness\"])))\n",
        "\n",
        "# Print all predictions and scores at once\n",
        "# for score, prediction in results:\n",
        "#     print(f'Score: {score}, Prediction: {prediction}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 40
        },
        "id": "6Vdt20kJWkes",
        "outputId": "2a2884da-23ff-4372-da03-e305ee71204e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<pre style='margin: 0px; padding: 0px; vertical-align: middle; padding-left: 8px; margin-left: -8px; border-radius: 0px; border-left: 1px solid rgba(127, 127, 127, 0.2); white-space: pre-wrap; font-family: ColfaxAI, Arial; font-size: 15px; line-height: 23px;'>        </pre>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import spearmanr\n",
        "\n",
        "results = pd.DataFrame(results, columns = [\"Score\", \"Prediction\"])\n",
        "\n",
        "correlation, p_value = spearmanr(results[\"Score\"], results[\"Prediction\"])\n",
        "\n",
        "print(\"Spearman Correlation Coefficient:\", np.round(correlation, 2))"
      ],
      "metadata": {
        "id": "c7uZv6mIyvpl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}