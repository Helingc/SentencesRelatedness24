{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shmuhammadd/semantic_relatedness/blob/main/Simple_English_Baseline_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndqGV9RrIyXX"
      },
      "source": [
        "# Simple Co-Occurance Baseline for Semantic Relatedness -- English Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gs77QultIyXY"
      },
      "source": [
        "Authors: Krishnapriya Vishnubhotla, Mohamed Abdalla\n",
        "\n",
        "Introduction:\n",
        "\n",
        "In this starter notebook, we will take you through the process of estimating semantic relatedness using simple co-occurance baselines. The notebook was adapted from a notebook for SemEval 2023 Shared Task 12: AfriSenti (Task A)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewwVGDM3IyXY"
      },
      "source": [
        "### Package Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "T6myajMlIyXZ"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import spearmanr, pearsonr\n",
        "import matplotlib.pyplot as plt\n",
        "import io\n",
        "from gensim.models import FastText\n",
        "plt.style.use('ggplot')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gn_ikaypIyXZ"
      },
      "source": [
        "### Data Import\n",
        "\n",
        "The training data will have a real-values semantic textual relatedness score (between 0 and 1) for a pair of English-language sentences.\n",
        "\n",
        "The data is structured as a CSV file with the following fields:\n",
        "- PairID: a unique identifier for the sentence pair\n",
        "- Text: two sentences separated by a newline ('\\n') character\n",
        "- Score: the semantic textual relatedness score for the two sentences\n",
        "\n",
        "Below we will show you how to load and re-format the provided data file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1PhipxbhIyXa",
        "outputId": "1da7308c-a799-4fe0-897e-3e4a23ea15c2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PairID</th>\n",
              "      <th>Text</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ENG-train-0000</td>\n",
              "      <td>It that happens, just pull the plug.\\nif that ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENG-train-0001</td>\n",
              "      <td>A black dog running through water.\\nA black do...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ENG-train-0002</td>\n",
              "      <td>I've been searchingthe entire abbey for you.\\n...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ENG-train-0003</td>\n",
              "      <td>If he is good looking and has a good personali...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ENG-train-0004</td>\n",
              "      <td>She does not hate you, she is just annoyed wit...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           PairID                                               Text  Score\n",
              "0  ENG-train-0000  It that happens, just pull the plug.\\nif that ...    1.0\n",
              "1  ENG-train-0001  A black dog running through water.\\nA black do...    1.0\n",
              "2  ENG-train-0002  I've been searchingthe entire abbey for you.\\n...    1.0\n",
              "3  ENG-train-0003  If he is good looking and has a good personali...    1.0\n",
              "4  ENG-train-0004  She does not hate you, she is just annoyed wit...    1.0"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the File\n",
        "df_str_rel = pd.read_csv('/Users/lemarx/Documents/01_projects/SentencesRelatedness24/data/raw/eng_train.csv')\n",
        "df_str_rel.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXA06vbeIyXb",
        "outputId": "14e7402d-bc57-44f0-8684-239d04330112"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['It that happens, just pull the plug.\\nif that ever happens, just pull the plug.',\n",
              "       'A black dog running through water.\\nA black dog is running through some water.',\n",
              "       \"I've been searchingthe entire abbey for you.\\nI'm looking for you all over the abbey.\",\n",
              "       ...,\n",
              "       \"I actually read a chapter or two beyond that point, but my heart wasn't in it any more.\\nLets say she's a blend of two types of beings.\",\n",
              "       'A boy gives being in the snow two thumbs up.\\nA satisfied cat is perched beside a crystal lamp.',\n",
              "       'Perhaps it is strange to think about sex constantly these days.\\nFew people know how to shoot pool these days.'],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_str_rel['Text'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5500"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df_str_rel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "2omI6W3pIyXb",
        "outputId": "0db14703-4eee-4a33-cabf-d885c3fc86b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['It that happens, just pull the plug.',\n",
              " 'if that ever happens, just pull the plug.']"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Creating a column \"Split_Text\" which is a list of two sentences.\n",
        "df_str_rel['Split_Text'] = df_str_rel['Text'].apply(lambda x: x.split(\"\\n\"))\n",
        "df_str_rel['Split_Text'].loc[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Irz_4Wm6IyXb"
      },
      "source": [
        "# Dice Score (Overlap Score)\n",
        "\n",
        "A simple baseline for estimating semantic relatedness between two sentences is to look at the proportion of words that they share in common.\n",
        "\n",
        "There are many ways to change the score below. Consider:\n",
        "1. Removing stop words and/or puncutation\n",
        "2. Counting duplicate words (currently not counted)\n",
        "3. Weighting rarer words differently\n",
        "4. Splitting tokens differently"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Jtr56u-BIyXc"
      },
      "outputs": [],
      "source": [
        "def dice_score(s1,s2):\n",
        "  s1 = s1.lower()\n",
        "  s1_split = re.findall(r\"\\w+|[^\\w\\s]\", s1, re.UNICODE)\n",
        "\n",
        "  s2 = s2.lower()\n",
        "  s2_split = re.findall(r\"\\w+|[^\\w\\s]\", s2, re.UNICODE)\n",
        "\n",
        "  dice_coef = len(set(s1_split).intersection(set(s2_split))) / (len(set(s1_split)) + len(set(s2_split)))\n",
        "  return round(dice_coef, 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSgeyGpiIyXc"
      },
      "source": [
        "## Calculate Dice Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/4t/_4f_khl520s03z4ltmxqlnsh0000gn/T/ipykernel_8836/593018851.py:1: DeprecationWarning: Call to deprecated `load_fasttext_format` (use load_facebook_vectors (to use pretrained embeddings) or load_facebook_model (to continue training with the loaded full model, more RAM) instead).\n",
            "  fasttext_model = FastText.load_fasttext_format('/Users/lemarx/Documents/01_projects/SentencesRelatedness24/data/embeddings/cc.en.300.bin')\n"
          ]
        }
      ],
      "source": [
        "fasttext_model = FastText.load_fasttext_format('/Users/lemarx/Documents/01_projects/SentencesRelatedness24/data/embeddings/cc.en.300.bin')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_vector = fasttext_model.wv['\\n']\n",
        "word_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def to_sent_emb(sentence):\n",
        "    sentence_emb = np.array([fasttext_model.wv[word] for word in sentence.split() if word in fasttext_model.wv]).mean(axis=0)\n",
        "    return sentence_emb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cosine_similarity(vector_a, vector_b):\n",
        "    vector_a = to_sent_emb(vector_a)\n",
        "    vector_b = to_sent_emb(vector_b)\n",
        "    dot_product = np.dot(vector_a, vector_b)\n",
        "    norm_a = np.linalg.norm(vector_a)\n",
        "    norm_b = np.linalg.norm(vector_b)\n",
        "\n",
        "    similarity = dot_product / (norm_a * norm_b)\n",
        "    return similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_str_rel['cos_sim'] = df_str_rel.apply(lambda row: cosine_similarity(row['Split_Text'][0],row['Split_Text'][1]), axis= 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8440153\n"
          ]
        }
      ],
      "source": [
        "sent_pair = df_str_rel['Split_Text'].loc[0]\n",
        "sim = cosine_similarity(sent_pair[0],sent_pair[1])\n",
        "print(sim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "SAMvGhTAIyXc"
      },
      "outputs": [],
      "source": [
        "true_scores = df_str_rel['Score'].values\n",
        "pred_scores = df_str_rel['cos_sim'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oK3FAYWJIyXd",
        "outputId": "7e3c926d-f118-429c-ceb1-8f11f2c902a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spearman Correlation: 0.35\n"
          ]
        }
      ],
      "source": [
        "# How well does the baseline correlate with human judgments?\n",
        "print(\"Spearman Correlation:\", round(spearmanr(true_scores,pred_scores)[0],2))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
